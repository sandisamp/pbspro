#!/usr/bin/env python3

# Copyright (C) 1994-2020 Altair Engineering, Inc.
# For more information, contact Altair at www.altair.com.
#
# This file is part of both the OpenPBS software ("OpenPBS")
# and the PBS Professional ("PBS Pro") software.
#
# Open Source License Information:
#
# OpenPBS is free software. You can redistribute it and/or modify it under
# the terms of the GNU Affero General Public License as published by the
# Free Software Foundation, either version 3 of the License, or (at your
# option) any later version.
#
# OpenPBS is distributed in the hope that it will be useful, but WITHOUT
# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
# FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Affero General Public
# License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
# Commercial License Information:
#
# PBS Pro is commercially licensed software that shares a common core with
# the OpenPBS software.  For a copy of the commercial license terms and
# conditions, go to: (http://www.pbspro.com/agreement.html) or contact the
# Altair Legal Department.
#
# Altair's dual-license business model allows companies, individuals, and
# organizations to create proprietary derivative works of OpenPBS and
# distribute them - whether embedded or bundled with other software -
# under a commercial license agreement.
#
# Use of Altair's trademarks, including but not limited to "PBS™",
# "OpenPBS®", "PBS Professional®", and "PBS Pro™" and Altair's logos is
# subject to Altair's trademark licensing policies.

import argparse
import copy
import fileinput
import json
import os
import platform
import shlex
import shutil
import subprocess
import sys
import threading
import time
from argparse import RawTextHelpFormatter

pbs_dirname = ''


def log_error(str_to_print):
    print('\033[91m' + "ERROR ::: " + str(str_to_print) + '\033[0m')


def log_info(str_to_print):
    t = time.localtime()
    current_time = time.strftime("%H:%M:%S", t)
    print('\033[1m' + current_time + " ---> " + str(str_to_print) + '\033[0m')


def log_warning(str_to_print):
    print('\033[93m' + "WARNING ::: " + str(str_to_print) + '\033[0m')


def get_services_list():
    services = []
    docker_container_process = subprocess.run(
        ["docker-compose", "-f", "docker-compose.json", "ps"], stdout=subprocess.PIPE)
    docker_container = str(docker_container_process.stdout)
    for val in docker_container.split('\\n'):
        if val.find('Up') != -1:
            services.append(val.split(' ')[0][:-2][3:])
    return services


def get_compose_file_services_list():
    compose_file = os.path.join(pbs_dirname, 'docker-compose.json')
    with open(compose_file) as f:
        compose_file = json.loads(f.read())
    return list(compose_file['services'].keys())


def run_cmd(cmd, return_output=False):
    '''
    Run a terminal command, and if needed return output of the command.
    '''
    cmd = shlex.split(cmd)
    try:
        a = subprocess.Popen(cmd, stdout=subprocess.PIPE)
        out, err = a.communicate()
        if a.returncode != 0:
            log_error("command failed")
            log_error(str(err))
        else:
            if return_output:
                return str(out)
    except Exception as e:
        log_error("The command failed.")
        log_error(e)


def run_docker_cmd(run_cmd, only_run_on='all'):
    '''
    Runs a docker command and on failure redirects user to the container terminal
    '''
    services = get_services_list()
    services.sort(reverse=True)  # we want server cmds to run first
    for service in services:
        cmd = "docker-compose -f docker-compose.json exec " + \
            service + " bash -c \'" + run_cmd + "\'"
        if only_run_on != 'all' and cmd.find(only_run_on) == -1:
            log_info('Skipping on service platform ' + service +
                     ' as command to only be run on ' + only_run_on)
            continue
        try:
            log_info(cmd)
            docker_cmd = shlex.split(cmd)
            a = subprocess.Popen(docker_cmd)
            a.communicate()
            if a.returncode != 0:
                log_error(
                    "docker cmd returned with non zero exit code, redirecting you to container terminal")
                docker_cmd = shlex.split(
                    "docker-compose -f docker-compose.json exec " + service + " bash -c \'cd /pbssrc && /bin/bash\'")
                subprocess.run(docker_cmd)
                os._exit(1)
        except Exception as e:
            log_error("Failed\n:")
            log_error(e)


def write_to_file(file_path, value):
    with open(file_path, "w+") as f:
        f.write(value)


def read_from_file(file_path):
    if not os.path.isfile(file_path):
        open(file_path, 'a').close()
    with open(file_path, 'r+') as f:
        val = f.read()
    return val


def commit_docker_image():
    '''
    Watch for readiness of ci containers to commit a new image
    '''

    images_to_commit = {}
    timeout = 0
    services = get_services_list()
    service_count = len(services)
    timeout_total = 1 * 60 * 60
    while service_count > 0 or timeout > timeout_total:
        time.sleep(15)
        timeout = timeout + 15
        status = read_from_file(os.path.join(
            pbs_dirname, '.commandloops', '.status'))
        for service in services:
            if str(status).find(service) != -1:
                services.remove(service)
                service_count = service_count-1
                image = (service.split('_', 1)[1][:-2]).replace('_', ':')
                image = image.replace("-", ".")
                images_to_commit[image] = service
    for key in images_to_commit:
        try:
            build_id = 'docker-compose -f docker-compose.json ps -q ' + \
                images_to_commit[key]
            build_id = run_cmd(build_id, True)
            build_id = build_id.split("'")[1]
            build_id = build_id[:12]
            image_name = (str(key).replace(':', '_')
                          ).replace('.', '-') + '_ci_pbs'
            # shortening the build id to 12 characters as is displayed by 'docker ps'
            # unlike 'docker-compose ps'  which shows full id
            cmd = 'docker commit '+build_id+' '+image_name+':latest'
            log_info(cmd)
            run_cmd(cmd)
        except Exception as e:
            log_error(e)
        try:
            bad_images = "docker images -qa -f'dangling=true'"
            bad_images = run_cmd(bad_images, True)
            if bad_images != "b''":
                bad_images = (bad_images.split("'")[1]).replace("\\n", " ")
                print("The following untagged images will be removed -> " + bad_images)
                cmd = 'docker rmi ' + bad_images
                run_cmd(cmd)
        except Exception as e:
            log_warning(
                "could not remove bad (dangling) images, please remove manually")
            print(e)
    return True


def get_pkgs(platform):
    build_cmd = '/src/build-pbs-packages.sh'
    if platform != 'called':
        try:
            subprocess.run([pbs_dirname + '/ci', '--delete'])
            subprocess.run([pbs_dirname + '/ci', '--start=' + platform])
        except:
            log_error('Failed to restart ci.')
    log_info('The package build logs can be found in logs/pkglogs')
    run_docker_cmd(build_cmd + ' | tee /logs/pkglogs')


def create_ts_tree_json():
    benchpress_opt = os.path.join(
        pbs_dirname, '.commandloops', '.benchpress_opt')
    benchpress_value = read_from_file(benchpress_opt)
    try:
        cmd = '/src/etc/gen_ptl_json.sh "' + benchpress_value + '"'
        run_docker_cmd(cmd, only_run_on='server')
    except:
        log_error('Failed to generate testsuite info json')


def get_node_config(node_image='centos:7'):
    json_data = {}
    max_servers_needed = 1
    max_moms_needed = 1
    max_comms_needed = 1
    no_mom_on_server_flag = False
    no_comm_on_mom_flag = True
    no_comm_on_server_flag = False
    try:
        with open(os.path.join(pbs_dirname, 'ptl_ts_tree.json')) as f:
            json_data = json.load(f)
    except:
        log_error('Could not find ptl tree json file')
    for ts in json_data.values():
        for tclist in ts['tclist'].values():
            max_moms_needed = max(
                tclist['requirements']['num_moms'], max_moms_needed)
            max_servers_needed = max(
                tclist['requirements']['num_servers'], max_servers_needed)
            max_comms_needed = max(
                tclist['requirements']['num_comms'], max_servers_needed)
            no_mom_on_server_flag = tclist['requirements']['no_mom_on_server'] or no_mom_on_server_flag
            no_comm_on_server_flag = tclist['requirements']['no_comm_on_server'] or no_comm_on_server_flag
            no_comm_on_mom_flag = tclist['requirements']['no_comm_on_mom'] or no_comm_on_mom_flag

    node_config = ''

    # get required number of servers and moms
    for _ in range(max_servers_needed):
        node_config = node_config+'server='+node_image+';'
    if no_mom_on_server_flag == False:
        max_moms_needed = max(max_moms_needed, max_servers_needed)
        if max_moms_needed > max_servers_needed:
            for _ in range(max_moms_needed - max_servers_needed):
                node_config = node_config + 'mom=' + node_image + ';'
    else:
        for _ in range(max_moms_needed):
            node_config = node_config + 'mom=' + node_image + ';'

    only_moms = node_config.count("mom=")
    # get required num of comms
    if no_comm_on_mom_flag == True and no_comm_on_server_flag == True:
        for _ in range(max_comms_needed):
            node_config = node_config + 'comm=' + node_image + ';'
    elif no_comm_on_mom_flag == True and no_comm_on_server_flag == False:
        if max_comms_needed > max_servers_needed:
            for _ in range(max_comms_needed-max_servers_needed):
                node_config = node_config + 'comm=' + node_image + ';'
    else:
        if max_comms_needed > only_moms:
            for _ in range(max_comms_needed - only_moms):
                node_config = node_config + 'comm=' + node_image + ';'

    # remove the trailing ';' from the node_config string
    node_config = node_config[:-1]
    return node_config


def find_ci():
    '''
    Finds absolute path of pbs and ci
    '''
    cur_dir = os.path.dirname(os.path.abspath(__file__))
    return os.path.dirname(cur_dir)


def tail_file():
    server_name = ''
    build_log_path = get_services_list()
    for i in build_log_path:
        if i.find('server') != -1:
            build_log_path = i
            server_name = i
    build_log_path = os.path.join(
        pbs_dirname, 'logs', 'build-' + build_log_path)
    prev = ''
    next = ''
    with open(build_log_path, 'rb') as f:
        while True:
            f.seek(-2, os.SEEK_END)
            while f.read(1) != b'\n':
                f.seek(-2, os.SEEK_CUR)
            next = f.readline().decode()
            if next != prev:
                print(next, end='')
                prev = next
            else:
                status_file = os.path.join(
                    pbs_dirname, '.commandloops', '.status')
                status_file = read_from_file(status_file)
                if status_file.find(server_name) != -1:
                    return


def check_for_existing_image(val='centos:7'):
    '''
    This function will check whether an existing image with the
    post-fix of '_ci_pbs' exists or not for the given docker image.
    '''
    if val.find('_ci_pbs') == -1:
        search_str = val.replace(":", "_")
        search_str = search_str.replace(".", '-')
        search_str += '_ci_pbs'
    cmd = 'docker images -q ' + search_str
    search_result = run_cmd(cmd, True)
    if search_result != "b''":
        return True, search_str
    else:
        return False, val


def get_current_setup():
    compose_file = os.path.join(pbs_dirname, 'docker-compose.json')
    node_config = ''
    with open(compose_file) as f:
        compose_file = json.loads(f.read())
    for service in compose_file['services']:
        image = compose_file["services"][service]['image']
        if image[-7:] == '_ci_pbs':
            image = image[:-7][::-1].replace('_', ':', 1)[::-1]
        node_type = compose_file["services"][service]['environment'][1]
        node_type = (node_type.split('=')[1])[:-1][1:]
        node_config += node_type + '=' + image + ';'
    node_config = node_config[:-1]
    return node_config


def load_conf():
    conf_file = os.path.join(pbs_dirname, '.commandloops', '.conf.json')
    with open(conf_file) as f:
        conf_file = json.loads(f.read())
    return conf_file


def show_set_opts():
    conf_opts = load_conf()
    os_file_list = get_compose_file_services_list()
    os_file_list.sort()
    conf_opts['OS'] = os_file_list
    print(json.dumps(conf_opts, indent=2, sort_keys=True))


def build_compose_file(nodes):
    compose_template = {
        "version": "3",
        "services": {
            "pbs-build": {
                "image": "centos:7",
                "volumes": [
                    "../:/pbssrc",
                    "./:/src",
                    "./logs:/logs",
                    "./etc:/workspace/etc"
                ],
                "entrypoint": "/workspace/etc/container-init \"/src/docker-entrypoint\"",
                "environment": [
                    "CLUSTER_INFO='SERVER=centos:7'",
                    "NODE_TYPE='server'",
                    "LC_ALL=en_US.utf-8",
                    "LANG=en_US.utf-8"
                ],
                "networks": {
                    "ci": {
                        "aliases": [
                            "pbs_server"
                        ]
                    }
                },
                "hostname": "pbs.ci",
                "user": "root",
                "privileged": True
            }
        },
        "networks": {
            "ci": {
                "driver": "bridge"
            }
        }
    }
    service_template_prist = compose_template['services']['pbs-build']
    service_template_prist['environment'][0] = 'CLUSTER_INFO=\'' + nodes + '\''
    del compose_template['services']['pbs-build']
    count = 0
    for n in nodes.split(';'):
        service_template = copy.deepcopy(service_template_prist)
        count = count + 1
        node_val = n.split('=')[1]
        node_key = n.split('=')[0]
        node_name = node_key + '_' + \
            (node_val.replace(':', '_')).replace('.', '-') + '_' + str(count)
        service_template['environment'][1] = 'NODE_TYPE=\'' + node_key + '\''
        service_template['networks']['ci']['aliases'][0] = node_name
        if node_key == 'server':
            service_template['networks']['ci']['aliases'].append('pbs_server')
        service_template['hostname'] = node_name
        image_value = node_val
        _, image_value = check_for_existing_image(node_val)
        service_template['image'] = image_value
        compose_template['services'][node_name] = service_template
    f = open(os.path.join(pbs_dirname, 'docker-compose.json'), 'w')
    json.dump(compose_template, f, indent=2, sort_keys=True)
    f.close()
    log_info("Configured nodes for ci")


def check_prerequisites():
    '''
    This function will check whether docker docker-compose commands are available
    or a container is that has pbs running.
    '''
    cmd = "where" if platform.system() == "Windows" else "which"

    try:
        subprocess.run([cmd, "docker"], stdout=subprocess.DEVNULL)
    except:
        log_error("docker not found in PATH")
        return 1

    try:
        subprocess.run([cmd, "docker-compose"], stdout=subprocess.DEVNULL)
    except:
        log_error("docker-compose not found in PATH")
        return 1

    try:
        docker_container_process = subprocess.run(
            ["docker-compose", "-f", "docker-compose.json", "ps"], stdout=subprocess.PIPE)
        docker_container = str(docker_container_process.stdout)
        if docker_container.find('Up') == -1:
            log_info("No running service found")
            try:
                log_info('Attempting to start container')
                os.chdir(pbs_dirname)
                subprocess.run(["docker-compose", "-f", "docker-compose.json", "down", "--remove-orphans"],
                               stdout=subprocess.DEVNULL)
                if os.path.exists(os.path.join(pbs_dirname, '.commandloops', '.status')):
                    os.remove(os.path.join(
                        pbs_dirname, '.commandloops', '.status'))
                write_to_file(os.path.join(
                    pbs_dirname, '.commandloops', '.status'), '')
                subprocess.run(
                    ["docker-compose", "-f", "docker-compose.json", "up", "-d"])
                log_info('Waiting for container build to complete ')
                build_log_path = os.path.join(pbs_dirname, 'logs')
                log_info("Build logs can be found in " + build_log_path)
                # wait for build to complete and commit newly built container
                tail_file()
                commit_docker_image()
            except Exception as e:
                log_error(e)
        else:
            log_info("running container found")
            return 0
    except:
        log_error(e)


def is_restart_required():
    create_ts_tree_json()
    current_file_services_list = get_compose_file_services_list()
    current_node_image = current_file_services_list[0].split(
        '_', 1)[1][:-2].replace('_', ':')
    node_config = get_node_config(node_image=current_node_image)
    potential_list = []
    for val in node_config.split(';'):
        val = val.replace('=', '_')
        val = val.replace(':', '_')
        potential_list.append(val)
    current_file_services_list = [i[:-2] for i in current_file_services_list]
    # compare without platform names
    current_file_services_list = [
        i.split('_', 1)[0] for i in current_file_services_list]
    potential_list = [i.split('_', 1)[0] for i in potential_list]
    potential_list.sort()
    current_file_services_list.sort()
    if current_file_services_list != potential_list:
        build_compose_file(node_config)
        return True
    else:
        return False


def initialise_command_loop():
    command_path = os.path.join(pbs_dirname, '.commandloops')
    if not os.path.exists(command_path):
        os.mkdir(command_path)
    target_path = os.path.join(command_path, '.conf.json')
    if not os.path.exists(target_path):
        value = '{ "configure": "--prefix=/opt/pbs --enable-ptl", "tests" : "-t SmokeTest" }'
        write_to_file(target_path, value)
    target_path = os.path.join(command_path, '.configure_opt')
    if not os.path.exists(target_path):
        value = "--prefix=/opt/pbs --enable-ptl"
        write_to_file(target_path, value)
    target_path = os.path.join(command_path, '.benchpress_opt')
    if not os.path.exists(target_path):
        value = "--tags=smoke"
        write_to_file(target_path, value)
    target_path = os.path.join(command_path, '.make')
    if not os.path.exists(target_path):
        value = "True"
        write_to_file(target_path, value)
    target_path = os.path.join(pbs_dirname, 'docker-compose.json')
    if not os.path.exists(target_path):
        build_compose_file('server=centos:7')
        run_cmd('docker-compose -f docker-compose.json down --remove-orphans')


if __name__ == "__main__":

    ap = argparse.ArgumentParser(
        prog='ci', description='Runs the ci tool for pbs', formatter_class=RawTextHelpFormatter,
        epilog='Examples of using arguments.\n\
        ./ci --run\n\
        ./ci --set \'OS=centos:7\'\n\
        ./ci --set "tests=-t SmokeTest"\n\
        ./ci --set "configure=CFLAGS=\'-g O2\' --enable-ptl"\n\
        ./ci --set "nodes=mom=centos:7;server=ubuntu:16.04"\n\
        ./ci --delete\n\
        ./ci --build-pkgs or ./ci --build-pkgs=\'ubuntu:16.04\'\n\
        ./ci --local\n\
\033[1mNote:Set tests as empty if you dont want to run PTL \033[0m',
        conflict_handler='resolve')
    ap.add_argument('--run', const='called',
                    help='runs the containers such that (if needed) will configure, make and install pbs and run tests (if not set as empty)', nargs='?')
    ap.add_argument('--set', const='called',
                    help='set configuration values for \033[1m | OS | nodes | configure | tests | \033[0m', nargs='?')
    ap.add_argument('--delete', const='called',
                    help='destroy pbs container', nargs='?')
    ap.add_argument('--build-pkgs', const='called',
                    help='build packages for the current platform. Optionally provide platform as argument', nargs='?')
    ap.add_argument('--local', const='called',
                    help='Simply run the travis script locally, without spawning any containers', nargs='?')
    if len(sys.argv) < 2:
        log_error('\nToo few arguments\n')
        ap.print_help()
        sys.exit(1)
    args = ap.parse_args(sys.argv[1:])
    pbs_dirname = find_ci()
    pbs_dirname = os.path.join(pbs_dirname, 'ci')
    os.chdir(pbs_dirname)
    build_log_path = os.path.join(pbs_dirname, 'logs')
    initialise_command_loop()
    if args.delete == None and args.local == None and args.set == None:
        ret = check_prerequisites()
        if ret == 1:
            log_error(
                "container build failed, build logs can be found in " + build_log_path)
            sys.exit(1)
    try:
        if args.set != None:
            if args.set != 'called':
                container_running = False
                conf_opts = load_conf()
                key = (args.set).split('=', 1)[0]
                value = (args.set).split('=', 1)[1]
                docker_container_process = subprocess.run(
                    ["docker-compose", "-f", "docker-compose.json", "ps"], stdout=subprocess.PIPE)
                docker_container = str(docker_container_process.stdout)
                for val in docker_container.split('\\n'):
                    if val.find('Up') != -1:
                        container_running = True
                if key == 'nodes':
                    if container_running:
                        log_error(
                            "Delete existing containers first with ./ci --delete")
                        os._exit(1)
                    build_compose_file(value)
                elif key == 'OS' or key == 'os':
                    if container_running:
                        log_error(
                            "Delete existing containers first with ./ci --delete")
                        os._exit(1)
                    node_string = value.replace('"', '')
                    node_string = 'server=' + node_string
                    build_compose_file(nodes=node_string)
                else:
                    if key in conf_opts:
                        conf_opts[key] = value
                        f = open(os.path.join(
                            pbs_dirname, '.commandloops', '.conf.json'), 'w')
                        json.dump(conf_opts, f, indent=2, sort_keys=True)
                        f.close()
                    else:
                        log_warning("Unrecognised key, nothing to update")
            log_info("These are the current options")
            show_set_opts()
        if args.build_pkgs != None:
            get_pkgs(args.build_pkgs)
        if args.run != None:
            command_path = os.path.join(pbs_dirname, '.commandloops')
            conf_opts = load_conf()
            if conf_opts['tests'] != '':
                target_path = os.path.join(command_path, '.benchpress_opt')
                write_to_file(target_path, conf_opts['tests'])
                if is_restart_required():
                    run_cmd(
                        "docker-compose -f docker-compose.json down --remove-orphans")
                    check_prerequisites()
            target_path = os.path.join(command_path, '.configure_opt')
            if conf_opts['configure'] != read_from_file(target_path):
                cmd = ' export ONLY_CONFIGURE=1 && /src/do.sh 2>&1 | tee -a /logs/build-$(hostname) '
                run_docker_cmd(cmd)
                write_to_file(target_path, conf_opts['configure'])
            target_path = os.path.join(command_path, '.make')
            if read_from_file(target_path) == 'True':
                cmd = ' export ONLY_REBUILD=1 && /src/do.sh 2>&1 | tee -a /logs/build-$(hostname) '
                run_docker_cmd(cmd)
                cmd = ' export ONLY_INSTALL=1 && /src/do.sh 2>&1 | tee -a /logs/build-$(hostname) '
                run_docker_cmd(cmd)
            target_path = os.path.join(command_path, '.benchpress_opt')
            if conf_opts['tests'] == '':
                write_to_file(target_path, conf_opts['tests'])
                log_warning("No tests assigned, skipping PTL run")
            else:
                write_to_file(target_path, conf_opts['tests'])
                cmd = 'export RUN_TESTS=1 && export ONLY_TEST=1 && /src/do.sh '
                run_docker_cmd(cmd, only_run_on='server')
        if args.delete != None:
            confirm = input(
                '\033[91mAre you sure you want to delete containers (Y/N)?: \033[0m')
            if confirm.lower() == 'no' or confirm.lower() == 'n':
                os._exit(0)
            elif confirm.lower() == 'yes' or confirm.lower() == 'y':
                services = get_services_list()
                if len(services) != 0:
                    build_compose_file(nodes=get_current_setup())
                    cmd = '/src/killit.sh backup'
                    run_docker_cmd(cmd, only_run_on='server')
                    log_warning('Removed logs file')
                    log_info('backup files can be found in ' + build_log_path)
                else:
                    log_info('No running container found, nothing to backup')
                try:
                    os.chdir(pbs_dirname)
                    run_cmd(
                        "docker-compose -f docker-compose.json down --remove-orphans")
                    log_info(
                        "done delete container and services")
                except Exception as e:
                    log_error("Failed to destroy container and services: " + e)
            else:
                log_error("Invalid option provided")
        if args.local != None:
            os.chdir(pbs_dirname)
            # using subprocess.run instead of run_cmd function so we dont supress stdout and stderr
            if args.local == 'called':
                exit_code = subprocess.run("./do.sh")
                sys.exit(exit_code.returncode)
            if args.local == 'sanitize':
                exit_code = subprocess.run("./do_sanitize_mode.sh")
                sys.exit(exit_code.returncode)
        else:
            sys.exit(0)
    except Exception as e:
        ap.print_help()
        log_error(e)
